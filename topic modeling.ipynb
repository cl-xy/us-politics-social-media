{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470e0006",
   "metadata": {},
   "source": [
    "## Purpose: Topic Modeling on Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af8d11",
   "metadata": {},
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff3af940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (3.3.1)\n",
      "Requirement already satisfied: setuptools in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (61.2.0)\n",
      "Requirement already satisfied: joblib in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (1.0.2)\n",
      "Requirement already satisfied: funcy in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (1.17)\n",
      "Requirement already satisfied: future in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: sklearn in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (0.0.post1)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (1.4.2)\n",
      "Requirement already satisfied: gensim in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (4.1.2)\n",
      "Requirement already satisfied: numexpr in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (1.21.5)\n",
      "Requirement already satisfied: jinja2 in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: scipy in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (1.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.2.0->pyLDAvis) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from gensim->pyLDAvis) (5.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from jinja2->pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: packaging in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from numexpr->pyLDAvis) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from packaging->numexpr->pyLDAvis) (3.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/rachelng/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->pyLDAvis) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76ed79",
   "metadata": {},
   "source": [
    "### Ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fb9c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5315e8",
   "metadata": {},
   "source": [
    "### Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "131cc23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d463d5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>collected_at</th>\n",
       "      <th>tweet_lang</th>\n",
       "      <th>tweet_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-15 00:00:02</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>#Trump: As a student I used to hear for years,...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>8436472</td>\n",
       "      <td>snarke</td>\n",
       "      <td>snarke</td>\n",
       "      <td>Will mock for food! Freelance writer, blogger,...</td>\n",
       "      <td>...</td>\n",
       "      <td>45.520247</td>\n",
       "      <td>-122.674195</td>\n",
       "      <td>Portland</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>OR</td>\n",
       "      <td>2020-10-21 00:00:00.746</td>\n",
       "      <td>en</td>\n",
       "      <td>['trump', 'student', 'use', 'hear', 'year', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-15 00:00:08</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>You get a tie! And you get a tie! #Trump ‚Äòs ra...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>47413798</td>\n",
       "      <td>Rana Abtar - ÿ±ŸÜÿß ÿ£ÿ®ÿ™ÿ±</td>\n",
       "      <td>Ranaabtar</td>\n",
       "      <td>Washington Correspondent, Lebanese-American ,c...</td>\n",
       "      <td>...</td>\n",
       "      <td>38.894992</td>\n",
       "      <td>-77.036558</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>DC</td>\n",
       "      <td>2020-10-21 00:00:01.493</td>\n",
       "      <td>en</td>\n",
       "      <td>['get', 'tie', 'get', 'tie', 'trump', 'ralli',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-15 00:00:17</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>@CLady62 Her 15 minutes were over long time ag...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1138416104</td>\n",
       "      <td>Farris Flagg</td>\n",
       "      <td>FarrisFlagg</td>\n",
       "      <td>#BidenHarris2020 #JoeBiden2020 #KamalaHarrisFo...</td>\n",
       "      <td>...</td>\n",
       "      <td>33.782519</td>\n",
       "      <td>-117.228648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>2020-10-21 00:00:01.866</td>\n",
       "      <td>en</td>\n",
       "      <td>['cladi', 'minut', 'long', 'time', 'ago', 'oma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-15 00:00:18</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>@DeeviousDenise @realDonaldTrump @nypost There...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>Stacey Gulledge üá∫üá∏ Patriot ‚ô•Ô∏è KAG üôè üëÆ‚Äç‚ôÄÔ∏è‚ô•Ô∏è</td>\n",
       "      <td>sm_gulledge</td>\n",
       "      <td>Patriot, Wife, ‚ÄúShaken not Stirred‚Äù Mom of two...</td>\n",
       "      <td>...</td>\n",
       "      <td>40.225357</td>\n",
       "      <td>-82.688140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>OH</td>\n",
       "      <td>2020-10-21 00:00:02.613</td>\n",
       "      <td>en</td>\n",
       "      <td>['deeviousdenis', 'realdonaldtrump', 'nypost',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-15 00:00:20</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>One of the single most effective remedies to e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>540476889</td>\n",
       "      <td>Jamieo</td>\n",
       "      <td>jamieo33</td>\n",
       "      <td>Don't know what I am. Can lean left and right,...</td>\n",
       "      <td>...</td>\n",
       "      <td>40.969989</td>\n",
       "      <td>-77.727883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA</td>\n",
       "      <td>2020-10-21 00:00:02.986</td>\n",
       "      <td>en</td>\n",
       "      <td>['one', 'singl', 'effect', 'remedi', 'erad', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at    tweet_id  \\\n",
       "0 2020-10-15 00:00:02 -2147483648   \n",
       "1 2020-10-15 00:00:08 -2147483648   \n",
       "2 2020-10-15 00:00:17 -2147483648   \n",
       "3 2020-10-15 00:00:18 -2147483648   \n",
       "4 2020-10-15 00:00:20 -2147483648   \n",
       "\n",
       "                                               tweet  likes  retweet_count  \\\n",
       "0  #Trump: As a student I used to hear for years,...      2              1   \n",
       "1  You get a tie! And you get a tie! #Trump ‚Äòs ra...      4              3   \n",
       "2  @CLady62 Her 15 minutes were over long time ag...      2              0   \n",
       "3  @DeeviousDenise @realDonaldTrump @nypost There...      0              0   \n",
       "4  One of the single most effective remedies to e...      0              0   \n",
       "\n",
       "                source     user_id  \\\n",
       "0      Twitter Web App     8436472   \n",
       "1   Twitter for iPhone    47413798   \n",
       "2  Twitter for Android  1138416104   \n",
       "3   Twitter for iPhone -2147483648   \n",
       "4      Twitter Web App   540476889   \n",
       "\n",
       "                                    user_name user_screen_name  \\\n",
       "0                                      snarke           snarke   \n",
       "1                       Rana Abtar - ÿ±ŸÜÿß ÿ£ÿ®ÿ™ÿ±        Ranaabtar   \n",
       "2                                Farris Flagg      FarrisFlagg   \n",
       "3  Stacey Gulledge üá∫üá∏ Patriot ‚ô•Ô∏è KAG üôè üëÆ‚Äç‚ôÄÔ∏è‚ô•Ô∏è      sm_gulledge   \n",
       "4                                      Jamieo         jamieo33   \n",
       "\n",
       "                                    user_description  ...        lat  \\\n",
       "0  Will mock for food! Freelance writer, blogger,...  ...  45.520247   \n",
       "1  Washington Correspondent, Lebanese-American ,c...  ...  38.894992   \n",
       "2  #BidenHarris2020 #JoeBiden2020 #KamalaHarrisFo...  ...  33.782519   \n",
       "3  Patriot, Wife, ‚ÄúShaken not Stirred‚Äù Mom of two...  ...  40.225357   \n",
       "4  Don't know what I am. Can lean left and right,...  ...  40.969989   \n",
       "\n",
       "         long        city        country      continent                 state  \\\n",
       "0 -122.674195    Portland  United States  North America                Oregon   \n",
       "1  -77.036558  Washington  United States  North America  District of Columbia   \n",
       "2 -117.228648         NaN  United States  North America            California   \n",
       "3  -82.688140         NaN  United States  North America                  Ohio   \n",
       "4  -77.727883         NaN  United States  North America          Pennsylvania   \n",
       "\n",
       "  state_code            collected_at tweet_lang  \\\n",
       "0         OR 2020-10-21 00:00:00.746         en   \n",
       "1         DC 2020-10-21 00:00:01.493         en   \n",
       "2         CA 2020-10-21 00:00:01.866         en   \n",
       "3         OH 2020-10-21 00:00:02.613         en   \n",
       "4         PA 2020-10-21 00:00:02.986         en   \n",
       "\n",
       "                                           tweet_new  \n",
       "0  ['trump', 'student', 'use', 'hear', 'year', 't...  \n",
       "1  ['get', 'tie', 'get', 'tie', 'trump', 'ralli',...  \n",
       "2  ['cladi', 'minut', 'long', 'time', 'ago', 'oma...  \n",
       "3  ['deeviousdenis', 'realdonaldtrump', 'nypost',...  \n",
       "4  ['one', 'singl', 'effect', 'remedi', 'erad', '...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('sample_cleaned.xlsx', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54fbd597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['trump', 'student', 'use', 'hear', 'year', 't...\n",
       "1    ['get', 'tie', 'get', 'tie', 'trump', 'ralli',...\n",
       "2    ['cladi', 'minut', 'long', 'time', 'ago', 'oma...\n",
       "3    ['deeviousdenis', 'realdonaldtrump', 'nypost',...\n",
       "4    ['one', 'singl', 'effect', 'remedi', 'erad', '...\n",
       "Name: tweet_new, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = df['tweet_new']\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39739db",
   "metadata": {},
   "source": [
    "### Topic Modeling by LDA\n",
    "https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb157338",
   "metadata": {},
   "source": [
    "#### Prepare data for LDA Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad668e",
   "metadata": {},
   "source": [
    "We start by tokenizing the text and removing stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc318498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rachelng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['student', 'use', 'hear', 'year', 'ten', 'year', 'heard', 'china', 'mani', 'ask', 'mani', 'sir', 'um']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['vote', 'get', 'twitter', 'elect', 'amp', 'one', 'go', 'like', 'nypost', 'would', 'know', 'presid', \n",
    "                   'dont', 'said', 'trump', 'say', 'want', 'post', 'peopl', 'potu', 'million', 'care', 'even', 'stori',\n",
    "                   'watch', 'realdonaldtrump', 'donaldtrump', 'biden', 'joebiden'])\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data = tweets.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d9da1",
   "metadata": {},
   "source": [
    "Then, we convert the tokenized object into a corpus and dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6418b546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08f8280",
   "metadata": {},
   "source": [
    "### LDA model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2463f318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.012*\"covid\" + 0.008*\"democrat\" + 0.007*\"impeach\" + 0.006*\"bidenharri\" + '\n",
      "  '0.006*\"antitrump\" + 0.005*\"corrupt\" + 0.005*\"campaign\" + 0.004*\"joe\" + '\n",
      "  '0.004*\"hunterbiden\" + 0.004*\"son\"'),\n",
      " (1,\n",
      "  '0.005*\"bidenharri\" + 0.005*\"year\" + 0.005*\"lie\" + 0.005*\"american\" + '\n",
      "  '0.004*\"give\" + 0.004*\"keep\" + 0.004*\"debat\" + 0.004*\"support\" + '\n",
      "  '0.004*\"corrupt\" + 0.004*\"time\"'),\n",
      " (2,\n",
      "  '0.006*\"covid\" + 0.005*\"news\" + 0.004*\"year\" + 0.004*\"support\" + 0.004*\"nbc\" '\n",
      "  '+ 0.004*\"look\" + 0.004*\"bidenharri\" + 0.004*\"plea\" + 0.004*\"never\" + '\n",
      "  '0.003*\"coronaviru\"'),\n",
      " (3,\n",
      "  '0.012*\"covid\" + 0.008*\"coronaviru\" + 0.007*\"hunterbiden\" + 0.006*\"usa\" + '\n",
      "  '0.006*\"bidenharri\" + 0.005*\"rp\" + 0.005*\"epstein\" + 0.005*\"hunter\" + '\n",
      "  '0.005*\"joe\" + 0.005*\"ue\"'),\n",
      " (4,\n",
      "  '0.008*\"hunterbiden\" + 0.006*\"covid\" + 0.005*\"lie\" + 0.004*\"via\" + '\n",
      "  '0.004*\"maga\" + 0.004*\"nbc\" + 0.004*\"hunter\" + 0.004*\"china\" + 0.004*\"see\" + '\n",
      "  '0.004*\"corrupt\"'),\n",
      " (5,\n",
      "  '0.005*\"joe\" + 0.005*\"corrupt\" + 0.005*\"day\" + 0.005*\"town\" + 0.005*\"hall\" + '\n",
      "  '0.004*\"think\" + 0.004*\"covid\" + 0.004*\"bidenharri\" + 0.004*\"debat\" + '\n",
      "  '0.004*\"campaign\"'),\n",
      " (6,\n",
      "  '0.009*\"maga\" + 0.006*\"bidenharri\" + 0.006*\"hunterbiden\" + 0.006*\"time\" + '\n",
      "  '0.005*\"usa\" + 0.005*\"american\" + 0.004*\"covid\" + 0.004*\"famili\" + '\n",
      "  '0.004*\"hunter\" + 0.004*\"nbc\"'),\n",
      " (7,\n",
      "  '0.012*\"covid\" + 0.007*\"bidenharri\" + 0.006*\"joe\" + 0.005*\"make\" + '\n",
      "  '0.005*\"right\" + 0.005*\"time\" + 0.004*\"democrat\" + 0.004*\"coronaviru\" + '\n",
      "  '0.004*\"day\" + 0.004*\"new\"'),\n",
      " (8,\n",
      "  '0.011*\"covid\" + 0.006*\"hunter\" + 0.005*\"corrupt\" + 0.005*\"democrat\" + '\n",
      "  '0.004*\"coronaviru\" + 0.004*\"instead\" + 0.004*\"thing\" + 0.004*\"never\" + '\n",
      "  '0.004*\"facebook\" + 0.004*\"usa\"'),\n",
      " (9,\n",
      "  '0.009*\"hunterbiden\" + 0.006*\"kamalaharri\" + 0.006*\"covid\" + '\n",
      "  '0.005*\"democrat\" + 0.005*\"america\" + 0.005*\"usa\" + 0.005*\"joe\" + '\n",
      "  '0.004*\"bidenharri\" + 0.004*\"lie\" + 0.003*\"son\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24404cb",
   "metadata": {},
   "source": [
    "### Analyzing LDA model results\n",
    "Refer to the html file in the topic_modeling_results directory for the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "if not os.path.exists('./topic_modeling_results/'):\n",
    "    os.mkdir('./topic_modeling_results')\n",
    "LDAvis_data_filepath = os.path.join('./topic_modeling_results/ldavis_prepared_'+str(num_topics))\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word, R=10)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './topic_modeling_results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
